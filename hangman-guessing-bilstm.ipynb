{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPdSkg1gOkk5N5PbCa9vBrD"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9608889,"sourceType":"datasetVersion","datasetId":5862987},{"sourceId":9610604,"sourceType":"datasetVersion","datasetId":5864220}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport collections\nimport time\nimport requests\nimport re\n\nclass HangmanAPI(object):\n    def __init__(self, access_token=None, session=None, timeout=None, model=None):\n        self.hangman_url = self.determine_hangman_url()\n        self.access_token = access_token\n        self.session = session or requests.Session()\n        self.timeout = timeout\n        self.guessed_letters = []\n        \n        # Load the full dictionary and precompute letter frequency\n        full_dictionary_location = \"/kaggle/input/word-250000/words_250000_train.txt\"\n        self.full_dictionary = self.build_dictionary(full_dictionary_location)\n        self.full_dictionary_common_letter_sorted = collections.Counter(\"\".join(self.full_dictionary)).most_common()\n        \n        # Initialize the current plausible dictionary as the full dictionary\n        self.current_dictionary = self.full_dictionary\n        \n        # Load the Bi-LSTM model if provided\n        self.model = model\n        if self.model:\n            self.model.eval()  # Set the model to evaluation mode\n        \n        # Initialize vowel prior probabilities (based on word length)\n        self.vowel_prior = self.initialize_vowel_prior()\n\n    def initialize_vowel_prior(self):\n        # Initialize vowel counts for each word length\n        vowel_counts = {length: collections.Counter() for length in range(1, 36)}  # Assuming max length of 35\n        \n        # Define the vowels\n        vowels = \"aeiou\"\n\n        # Count vowels for each word length\n        for word in self.full_dictionary:\n            word_length = len(word)\n            if word_length <= 35:  # Only consider words with lengths up to 35\n                for char in word:\n                    if char in vowels:\n                        vowel_counts[word_length][char] += 1\n        \n        # Normalize counts to get probabilities\n        vowel_prior = {}\n        for length, counts in vowel_counts.items():\n            total = sum(counts.values())\n            if total > 0:\n                vowel_prior[length] = {vowel: count / total for vowel, count in counts.items()}\n            else:\n                vowel_prior[length] = {vowel: 0 for vowel in vowels}  # No vowels for this length\n        \n        return vowel_prior\n\n    @staticmethod\n    def determine_hangman_url():\n        links = ['https://trexsim.com', 'https://sg.trexsim.com']\n        data = {link: 0 for link in links}\n\n        for link in links:\n            requests.get(link)\n            for i in range(10):\n                s = time.time()\n                requests.get(link)\n                data[link] = time.time() - s\n\n        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n        link += '/trexsim/hangman'\n        return link\n\n    def character_encoding(self, word):\n        # Encode each character to its index in the alphabet (1-26), treating _ as 0 for padding\n        encoded_word = [(ord(c) - ord('a') + 1) if 'a' <= c <= 'z' else 0 for c in word]\n        return self.onehot_encoding(encoded_word)\n\n    def onehot_encoding(self, vector, max_len=30):\n        # Padding or truncating the sequence to the fixed length (max_len)\n        padded_vector = [0] * max_len\n        for i, v in enumerate(vector[:max_len]):\n            padded_vector[i] = v\n        return torch.tensor(padded_vector, dtype=torch.long).unsqueeze(0)  # Add batch dimension for the model\n\n    def next_letter_prediction(self, encoding):\n        # Predict the next letter using the Bi-LSTM model\n        with torch.no_grad():\n            predictions = self.model(encoding)\n            probabilities = torch.softmax(predictions, dim=-1)\n            \n            # Filter out already guessed letters\n            for i in range(probabilities.shape[1]):\n                if chr(i + ord('a')) in self.guessed_letters:\n                    probabilities[0][i] = 0\n            return probabilities\n\n    def guess(self, word, tries_remains):\n        \"\"\"\n        Predict the next letter using vowel prior for the first 4 incorrect guesses,\n        and switch to Bi-LSTM model after that.\n        \"\"\"\n        # Clean the word and prepare for matching with dictionary\n        clean_word = word[::2].replace(\"_\", \".\")\n        len_word = len(clean_word)\n\n        # Guess using vowel prior if tries remain > 4\n        if tries_remains > 3:\n            vowels = list(self.vowel_prior.get(len_word, {}).keys())\n            if vowels:\n                # Sort vowels based on their prior probabilities and guess the highest one\n                guess_letter = max(vowels, key=lambda v: self.vowel_prior[len_word][v] if v in self.vowel_prior[len_word] else 0)\n                if guess_letter not in self.guessed_letters:\n                    self.guessed_letters.append(guess_letter)\n                    return guess_letter\n        \n        # Grab the current dictionary of possible words and initialize a new dictionary\n        new_dictionary = []\n        \n        # Filter plausible words from the current dictionary\n        for dict_word in self.current_dictionary:\n            if len(dict_word) == len_word and re.match(clean_word, dict_word):\n                new_dictionary.append(dict_word)\n        \n        # Update the current dictionary with the reduced set of plausible words\n        self.current_dictionary = new_dictionary\n        \n        # Attempt to predict the next letter using the Bi-LSTM model after 4 tries\n        guess_letter = '!'\n        if self.model and new_dictionary and tries_remains <= 4:\n            # If the model is available and there are plausible words, predict\n            encoding = self.character_encoding(clean_word)\n            probabilities = self.next_letter_prediction(encoding)\n            predicted_index = torch.argmax(probabilities, dim=1).item()\n            guess_letter = chr(predicted_index + ord('a'))\n\n        # If no model or no suitable prediction, fall back to frequency-based guessing\n        if guess_letter == '!':\n            full_dict_string = \"\".join(new_dictionary)\n            c = collections.Counter(full_dict_string)\n            sorted_letter_count = c.most_common()\n\n            for letter, _ in sorted_letter_count:\n                if letter not in self.guessed_letters:\n                    guess_letter = letter\n                    break\n\n            # Fallback to full dictionary frequency if no match found\n            if guess_letter == '!':\n                sorted_letter_count = self.full_dictionary_common_letter_sorted\n                for letter, _ in sorted_letter_count:\n                    if letter not in self.guessed_letters:\n                        guess_letter = letter\n                        break\n        \n        # Add the guessed letter to the list of guessed letters\n        self.guessed_letters.append(guess_letter)\n        return guess_letter\n\n    ##########################################################\n    # You'll likely not need to modify any of the code below #\n    ##########################################################\n    \n    def build_dictionary(self, dictionary_file_location):\n        text_file = open(dictionary_file_location, \"r\")\n        full_dictionary = text_file.read().splitlines()\n        text_file.close()\n        return full_dictionary\n                \n    def start_game(self, practice=True, verbose=True):\n        # Reset guessed letters and current plausible dictionary\n        self.guessed_letters = []\n        self.current_dictionary = self.full_dictionary\n                         \n        response = self.request(\"/new_game\", {\"practice\": practice})\n        if response.get('status') == \"approved\":\n            game_id = response.get('game_id')\n            word = response.get('word')\n            tries_remains = response.get('tries_remains')\n            if verbose:\n                print(f\"Successfully started a new game! Game ID: {game_id}. # of tries remaining: {tries_remains}. Word: {word}.\")\n            while tries_remains > 0:\n                guess_letter = self.guess(word, tries_remains)  # Get guessed letter from the guess function\n                if verbose:\n                    print(f\"Guessing letter: {guess_letter}\")\n                    \n                # Append guessed letter to guessed letters list\n                self.guessed_letters.append(guess_letter)\n                \n                try:\n                    res = self.request(\"/guess_letter\", {\"request\": \"guess_letter\", \"game_id\": game_id, \"letter\": guess_letter})\n                except HangmanAPIError:\n                    print('HangmanAPIError exception caught on request.')\n                    continue\n                except Exception as e:\n                    print('Other exception caught on request.')\n                    raise e\n               \n                if verbose:\n                    print(f\"Server response: {res}\")\n                \n                status = res.get('status')\n                tries_remains = res.get('tries_remains')\n                if status == \"success\":\n                    if verbose:\n                        print(f\"Successfully finished game: {game_id}\")\n                    return True\n                elif status == \"failed\":\n                    reason = res.get('reason', '# of tries exceeded!')\n                    if verbose:\n                        print(f\"Failed game: {game_id}. Reason: {reason}\")\n                    return False\n                elif status == \"ongoing\":\n                    word = res.get('word')\n        else:\n            if verbose:\n                print(\"Failed to start a new game\")\n        return False\n\n    def my_status(self):\n        return self.request(\"/my_status\", {})\n\n    def request(self, path, args=None, post_args=None, method=None):\n        if args is None:\n            args = dict()\n        if post_args is not None:\n            method = \"POST\"\n\n        if self.access_token:\n            if post_args and \"access_token\" not in post_args:\n                post_args[\"access_token\"] = self.access_token\n            elif \"access_token\" not in args:\n                args[\"access_token\"] = self.access_token\n\n        time.sleep(0.2)\n        num_retry, time_sleep = 50, 2\n        for it in range(num_retry):\n            try:\n                response = self.session.request(\n                    method or \"GET\",\n                    self.hangman_url + path,\n                    timeout=self.timeout,\n                    params=args,\n                    data=post_args,\n                    verify=False\n                )\n                break\n            except requests.HTTPError as e:\n                response = json.loads(e.read())\n                raise HangmanAPIError(response)\n            except requests.exceptions.SSLError as e:\n                if it + 1 == num_retry:\n                    raise\n                time.sleep(time_sleep)\n\n        headers = response.headers\n        if 'json' in headers['content-type']:\n            result = response.json()\n        elif \"access_token\" in parse_qs(response.text):\n            query_str = parse_qs(response.text)\n            if \"access_token\" in query_str:\n                result = {\"access_token\": query_str[\"access_token\"][0]}\n                if \"expires\" in query_str:\n                    result[\"expires\"] = query_str[\"expires\"][0]\n            else:\n                raise HangmanAPIError(response.json())\n        else:\n            raise HangmanAPIError('Maintype was not text, or querystring')\n\n        if result and isinstance(result, dict) and result.get(\"error\"):\n            raise HangmanAPIError(result)\n        return result\n\nclass HangmanAPIError(Exception):\n    def __init__(self, result):\n        self.result = result\n        self.code = None\n        try:\n            self.type = result[\"error_code\"]\n        except (KeyError, TypeError):\n            self.type = \"\"\n\n        try:\n            self.message = result[\"error_description\"]\n        except (KeyError, TypeError):\n            try:\n                self.message = result[\"error\"][\"message\"]\n                self.code = result[\"error\"].get(\"code\")\n                if not self.type:\n                    self.type = result[\"error\"].get(\"type\", \"\")\n            except (KeyError, TypeError):\n                try:\n                    self.message = result[\"error_msg\"]\n                except (KeyError, TypeError):\n                    self.message = result\n\n        Exception.__init__(self, self.message)\n","metadata":{"id":"ZO3wyKamNxma","execution":{"iopub.status.busy":"2024-10-12T20:21:41.287866Z","iopub.execute_input":"2024-10-12T20:21:41.288226Z","iopub.status.idle":"2024-10-12T20:21:41.334308Z","shell.execute_reply.started":"2024-10-12T20:21:41.288184Z","shell.execute_reply":"2024-10-12T20:21:41.333416Z"},"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"code","source":"!pip install tqdm\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijZUE9qxlYAD","executionInfo":{"status":"ok","timestamp":1728736001031,"user_tz":-330,"elapsed":2661,"user":{"displayName":"Avishi Gupta","userId":"18207377111502422005"}},"outputId":"b014fe79-7fa6-40ae-a57b-37eafbadfde4","execution":{"iopub.status.busy":"2024-10-12T18:08:22.626347Z","iopub.execute_input":"2024-10-12T18:08:22.627188Z","iopub.status.idle":"2024-10-12T18:08:34.889968Z","shell.execute_reply.started":"2024-10-12T18:08:22.627147Z","shell.execute_reply":"2024-10-12T18:08:34.888842Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"a07M3fCuladj","execution":{"iopub.status.busy":"2024-10-12T18:10:36.234399Z","iopub.execute_input":"2024-10-12T18:10:36.235377Z","iopub.status.idle":"2024-10-12T18:10:36.239505Z","shell.execute_reply.started":"2024-10-12T18:10:36.235334Z","shell.execute_reply":"2024-10-12T18:10:36.238406Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport time  # For timing the training duration\n\nclass BiLSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, max_len):\n        super(BiLSTM, self).__init__()\n        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim, padding_idx=0)  # +1 for padding\n        self.bilstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, output_size)  # Bi-directional output\n\n    def forward(self, x):\n        x = self.embedding(x)\n        lstm_out, _ = self.bilstm(x)\n        final_output = lstm_out[:, -1, :]  # Take output from the last time step\n        out = self.fc(final_output)\n        return out\n\n# Training the Bi-LSTM model\ndef train_model(model, train_loader, criterion, optimizer, num_epochs=10, print_freq=100):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        start_time = time.time()  # Start timer for the epoch\n        \n        # tqdm progress bar for batch processing\n        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n        \n        for i, (inputs, targets) in enumerate(progress_bar):\n            inputs, targets = inputs.long(), targets.long()\n\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Accumulate running loss\n            running_loss += loss.item()\n\n            # Only update the tqdm display every 'print_freq' batches\n            if (i + 1) % print_freq == 0 or (i + 1) == len(train_loader):\n                progress_bar.set_postfix(epoch_loss=f'{running_loss / (i + 1):.4f}')  # Update loss less frequently\n\n        # End of the epoch: calculate and print average loss and elapsed time\n        end_time = time.time()\n        epoch_duration = end_time - start_time\n        avg_loss = running_loss / len(train_loader)  # Calculate the average loss for this epoch\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Time: {epoch_duration:.2f} seconds\")\n\n    # Save the model after training\n    save_path = '/kaggle/working/bilstm_hangman_model.pt'\n    torch.save(model.state_dict(), save_path)\n    print(f\"Model saved at {save_path}\")\n\n\n# Prepare DataLoader for training\nfrom torch.utils.data import TensorDataset, DataLoader\n\ndef create_dataloaders(X, y, batch_size=64):\n    dataset = TensorDataset(torch.tensor(X), torch.tensor(y))\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Load dictionary function\ndef load_dictionary(file_path):\n    with open(file_path, 'r') as file:\n        dictionary = file.readlines()\n    return dictionary\n\n# Usage example\nif __name__ == \"__main__\":\n    # Hyperparameters\n    embedding_dim = 50\n    hidden_dim = 64\n    output_size = 26  # Predict a letter from 'a' to 'z'\n    max_len = 30  # Maximum sequence length\n    num_epochs = 10\n    batch_size = 256\n    print_freq = 500  # Update loss every 500 batches\n\n    # Initialize Hangman model and Bi-LSTM model\n    hangman_model = HangmanModel(vocab_size=26, embedding_dim=embedding_dim, max_len=max_len)\n\n    # Load the dictionary (list of words)\n    dictionary_path = '/kaggle/input/words-250000-train/words_250000_train.txt'  # Replace with your dictionary file path\n    dictionary = load_dictionary(dictionary_path)\n\n    # Generate the training data (X, y)\n    X, y = hangman_model.generate_data(dictionary)\n\n    # Create DataLoader\n    train_loader = create_dataloaders(X, y, batch_size)\n\n    # Initialize Bi-LSTM model\n    model = BiLSTM(vocab_size=26, embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=output_size, max_len=max_len)\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # Train and save the model\n    train_model(model, train_loader, criterion, optimizer, num_epochs=num_epochs, print_freq=print_freq)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaMOPxisWS2P","outputId":"d0fd1b65-c1b9-4623-88e5-2959eb50481d","execution":{"iopub.status.busy":"2024-10-12T18:10:46.541322Z","iopub.execute_input":"2024-10-12T18:10:46.541676Z","iopub.status.idle":"2024-10-12T19:43:58.051138Z","shell.execute_reply.started":"2024-10-12T18:10:46.541642Z","shell.execute_reply":"2024-10-12T19:43:58.050057Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 1.9867, Time: 564.16 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Loss: 1.4846, Time: 558.13 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Loss: 1.3635, Time: 557.41 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Loss: 1.2975, Time: 556.29 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10, Loss: 1.2549, Time: 553.99 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10, Loss: 1.2242, Time: 555.74 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10, Loss: 1.2000, Time: 563.03 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10, Loss: 1.1817, Time: 556.84 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10, Loss: 1.1661, Time: 548.76 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   ","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10, Loss: 1.1532, Time: 554.62 seconds\nModel saved at /kaggle/working/bilstm_hangman_model.pt\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Assuming the model has been loaded as before\n    hangman_model = HangmanModel(vocab_size=26, embedding_dim=50, max_len=30)\n    model = BiLSTM(vocab_size=26, embedding_dim=50, hidden_dim=64, output_size=26, max_len=30)\n    model.load_state_dict(torch.load('/kaggle/working/bilstm_hangman_model.pt'))\n    model.eval()\n\n    # Test with a masked word\n    masked_word = \"p_werhouse\"\n    \n    # Predict the next letter\n    predicted_letter = hangman_model.predict_and_update(masked_word, model)\n    print(f\"Predicted letter: {predicted_letter}\")\n    print(f\"Guessed letters: {hangman_model.guessed_letters}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-12T19:51:59.125936Z","iopub.execute_input":"2024-10-12T19:51:59.126785Z","iopub.status.idle":"2024-10-12T19:51:59.141972Z","shell.execute_reply.started":"2024-10-12T19:51:59.126745Z","shell.execute_reply":"2024-10-12T19:51:59.140927Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Predicted letter: o\nGuessed letters: {'o'}\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/480637435.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/working/bilstm_hangman_model.pt'))\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import json\nimport requests\nimport random\nimport string\nimport secrets\nimport time\nimport re\nimport collections\n\ntry:\n    from urllib.parse import parse_qs, urlencode, urlparse\nexcept ImportError:\n    from urlparse import parse_qs, urlparse\n    from urllib import urlencode\n\nfrom requests.packages.urllib3.exceptions import InsecureRequestWarning\n\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T19:54:20.071746Z","iopub.execute_input":"2024-10-12T19:54:20.072141Z","iopub.status.idle":"2024-10-12T19:54:20.152122Z","shell.execute_reply.started":"2024-10-12T19:54:20.072104Z","shell.execute_reply":"2024-10-12T19:54:20.151335Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class HangmanAPI(object):\n    def __init__(self, access_token=None, session=None, timeout=None):\n        self.hangman_url = self.determine_hangman_url()\n        self.access_token = access_token\n        self.session = session or requests.Session()\n        self.timeout = timeout\n        self.guessed_letters = []\n        \n        full_dictionary_location = \"words_250000_train.txt\"\n        self.full_dictionary = self.build_dictionary(full_dictionary_location)        \n        self.full_dictionary_common_letter_sorted = collections.Counter(\"\".join(self.full_dictionary)).most_common()\n        \n        self.current_dictionary = []\n        \n    @staticmethod\n    def determine_hangman_url():\n        links = ['https://trexsim.com', 'https://sg.trexsim.com']\n\n        data = {link: 0 for link in links}\n\n        for link in links:\n\n            requests.get(link)\n\n            for i in range(10):\n                s = time.time()\n                requests.get(link)\n                data[link] = time.time() - s\n\n        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n        link += '/trexsim/hangman'\n        return link","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"api = HangmanAPI(access_token=\"b10d926d7c581f8b023c673a54bf4f\", timeout=2000)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T20:10:06.280916Z","iopub.execute_input":"2024-10-12T20:10:06.281309Z","iopub.status.idle":"2024-10-12T20:10:25.387070Z","shell.execute_reply.started":"2024-10-12T20:10:06.281270Z","shell.execute_reply":"2024-10-12T20:10:25.386220Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"api.start_game(practice=1,verbose=True)\n[total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\npractice_success_rate = total_practice_successes / total_practice_runs\nprint('run %d practice games out of an allotted 100,000. practice success rate so far = %.3f' % (total_practice_runs, practice_success_rate))","metadata":{"execution":{"iopub.status.busy":"2024-10-12T20:22:11.729181Z","iopub.execute_input":"2024-10-12T20:22:11.729656Z","iopub.status.idle":"2024-10-12T20:22:14.206034Z","shell.execute_reply.started":"2024-10-12T20:22:11.729617Z","shell.execute_reply":"2024-10-12T20:22:14.205183Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Successfully started a new game! Game ID: e47269079e10. # of tries remaining: 6. Word: _ _ _ _ _ .\nGuessing letter: a\nServer response: {'game_id': 'e47269079e10', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ _ _ '}\nGuessing letter: e\nServer response: {'game_id': 'e47269079e10', 'status': 'ongoing', 'tries_remains': 4, 'word': '_ _ _ _ _ '}\nGuessing letter: s\nServer response: {'game_id': 'e47269079e10', 'status': 'ongoing', 'tries_remains': 4, 'word': '_ s _ _ _ '}\nGuessing letter: i\nServer response: {'game_id': 'e47269079e10', 'status': 'ongoing', 'tries_remains': 4, 'word': 'i s _ _ _ '}\nGuessing letter: m\nServer response: {'game_id': 'e47269079e10', 'status': 'ongoing', 'tries_remains': 3, 'word': 'i s _ _ _ '}\nGuessing letter: l\nServer response: {'game_id': 'e47269079e10', 'status': 'ongoing', 'tries_remains': 3, 'word': 'i s _ l _ '}\nGuessing letter: o\nServer response: {'game_id': 'e47269079e10', 'status': 'ongoing', 'tries_remains': 3, 'word': 'i s o l _ '}\nGuessing letter: n\nServer response: {'game_id': 'e47269079e10', 'status': 'success', 'tries_remains': 3, 'word': 'i s o l n '}\nSuccessfully finished game: e47269079e10\nrun 20 practice games out of an allotted 100,000. practice success rate so far = 0.250\n","output_type":"stream"}],"execution_count":42}]}